{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6917177,"sourceType":"datasetVersion","datasetId":3889865}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cancer Detection With Tiles\n\nTry detection with tiles, where for each large image, we randomly select a tile and assign it the original image's label. \n\nWe can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \nWe can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-11-02T16:11:09.318503Z","iopub.execute_input":"2023-11-02T16:11:09.318811Z","iopub.status.idle":"2023-11-02T16:11:09.327423Z","shell.execute_reply.started":"2023-11-02T16:11:09.318777Z","shell.execute_reply":"2023-11-02T16:11:09.326036Z"}}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\nimport torch\nfrom torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights, convnext_base, ConvNeXt_Base_Weights, convnext_small, ConvNeXt_Small_Weights, efficientnet_b4, EfficientNet_B4_Weights\nimport torch.nn as nn\nimport torch.optim as optim\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\nfrom typing import List, Dict, Optional\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\nimport random\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nimport random\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:39:42.838113Z","iopub.execute_input":"2023-12-15T19:39:42.839159Z","iopub.status.idle":"2023-12-15T19:40:04.019317Z","shell.execute_reply.started":"2023-12-15T19:39:42.839125Z","shell.execute_reply":"2023-12-15T19:40:04.017328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base Classes","metadata":{}},{"cell_type":"code","source":"class AugmentationTransforms:\n    def __init__(self, image_size: int):\n        self.image_size = image_size\n\n    def get_training_augmentation(self):\n        train_transform = [\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            albu.augmentations.transforms.GaussNoise(p=0.2),\n            albu.OneOf(\n                [\n                    albu.CLAHE(p=1),\n                    albu.RandomBrightnessContrast(p=1),\n                    albu.RandomGamma(p=1),\n                    albu.HueSaturationValue(p=1),\n                ],\n                p=0.5,\n            ),\n#             albu.OneOf(\n#                 [\n#                     albu.augmentations.transforms.Sharpen(p=1),\n#                     albu.Blur(blur_limit=3, p=1),\n#                     albu.MotionBlur(blur_limit=3, p=1),\n#                 ],\n#                 p=0.5,\n#             ),\n              albu.augmentations.geometric.resize.Resize(\n                self.image_size, self.image_size, always_apply=True\n            ),\n        ]\n        return albu.Compose(train_transform)\n\n    def get_validation_augmentation(self):\n        \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n        test_transform = [\n            albu.augmentations.geometric.resize.Resize(\n                self.image_size, self.image_size, always_apply=True\n            ),\n        ]\n        return albu.Compose(test_transform)\n\n    def get_preprocessing(self):\n        \"\"\"Construct preprocessing transform\n\n        Args:\n            preprocessing_fn (callbale): data normalization function\n                (can be specific for each pretrained neural network)\n        Return:\n            transform: albumentations.Compose\n\n        \"\"\"\n\n        # Model expects input [N, C, H, W]\n        # ToTensor convert HWC image to CHW image\n        ubc_mean = [0.8894420586142374,0.8208752169441305,0.8864016141389351]\n        ubc_std = [0.10106393015358608,0.15637655015581306,0.09892687853183287]\n        transform = [\n            albu.Normalize(mean=ubc_mean, std=ubc_std),\n            ToTensorV2(),\n        ]\n\n        return albu.Compose(transform)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:40:04.021866Z","iopub.execute_input":"2023-12-15T19:40:04.022529Z","iopub.status.idle":"2023-12-15T19:40:04.034767Z","shell.execute_reply.started":"2023-12-15T19:40:04.022491Z","shell.execute_reply":"2023-12-15T19:40:04.033348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport pandas as pd\nimport cv2\n\n\nclass CancerDataset(Dataset):\n    def __init__(\n        self,\n        data_df: pd.DataFrame,\n        black_threshold: int = 20,\n        max_bg_threshold: float = 0.35,\n        preprocessing=None,\n        augmentation=None,\n    ):\n        self.data_df = data_df\n        self.black_threshold = black_threshold\n        self.max_bg_threshold = max_bg_threshold\n        self.preprocessing = preprocessing\n        self.augmentation = augmentation\n\n        self.classes = [\"HGSC\", \"LGSC\", \"EC\", \"CC\", \"MC\"]\n        self.class2idx = {label: idx for idx, label in enumerate(self.classes)}\n\n        self.data_df.loc[:, \"label\"] = self.data_df.loc[:, \"label\"].map(self.class2idx)\n\n        \n        # Get filenames\n        slice_dir = Path(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/\")\n        slice_mask_dir = Path(\n            \"/kaggle/input/ubc-ocean-tiles-w-masks-2048px-scale-0-25/train_images\"\n        )\n        # Annotations contain pixel values\n        # Mask contains only values 0,1,2,3 for different classes\n        self.mask_dir = Path(\n            \"/kaggle/input/ubc-ocean-tiles-w-masks-2048px-scale-0-25/train_annotations\"\n        )\n        self.images_lists = []\n\n        print(\"Generating image list\")\n        for idx, image in self.data_df.iterrows():\n            if image[\"has_mask\"]:\n                images = list(\n                    (slice_mask_dir / str(image[\"image_id\"])).rglob(\"**/*.png\")\n                )\n            else:\n                images = list((slice_dir / str(image[\"image_id\"])).rglob(\"**/*.png\"))\n                \n            self.images_lists.append(images)\n        print(\"Done\")\n\n    def __getitem__(self, i):\n        image_id, label, _, _, _, has_mask = self.data_df.iloc[i]\n\n        image_id_list = self.images_lists[i]\n        random.shuffle(image_id_list)\n\n        # We make a copy so we don't skip elements, when remove some elements\n        # It takes to long to check, if all slices have tumor, so we do this procedurally\n        for img_path in image_id_list.copy():\n            img = cv2.imread(str(img_path))\n            \n            # If mask, check for tumor\n            if has_mask:\n                mask_slice = self.mask_dir / str(image_id) / img_path.name   \n                mask_slice_img = cv2.imread(str(mask_slice))\n                mask_slice_img = cv2.cvtColor(mask_slice_img, cv2.COLOR_BGR2RGB)\n                \n                # Check if the slice contains tumor\n                # All non zero values in red channel are for tumor\n                if np.all(mask_slice_img[..., 0] == 0):\n                    # If mask has no tumor, then remove it\n                    image_id_list.remove(img_path)\n                    continue\n            \n            # If there not too much background, the exit the loop and serve the image\n            black_bg = np.sum(img, axis=2) <= self.black_threshold\n            if np.sum(black_bg) <= (np.prod(black_bg.shape[:2]) * self.max_bg_threshold):\n                break\n\n        # Replace black pixels with white pixels\n        img[img <= self.black_threshold] = 255\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if self.augmentation:\n            img = self.augmentation(image=img)[\"image\"]\n\n        if self.preprocessing:\n            img = self.preprocessing(image=img)[\"image\"]\n\n        return img, label\n\n    def __len__(self):\n        return len(self.data_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:40:04.037854Z","iopub.execute_input":"2023-12-15T19:40:04.039113Z","iopub.status.idle":"2023-12-15T19:40:04.059239Z","shell.execute_reply.started":"2023-12-15T19:40:04.039067Z","shell.execute_reply":"2023-12-15T19:40:04.057797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CancerDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        image_size: int,\n        batch_size: int,\n        cutoff: float = 0.8,\n        black_threshold: int = 20,\n        max_bg_threshold: float = 0.35,\n        shuffle: Optional[bool] = True,\n    ):\n        super().__init__()\n        self.image_size = image_size\n        self.train_batch_size = batch_size\n        self.shuffle = shuffle\n        self.cutoff = cutoff\n        self.black_threshold = black_threshold\n        self.max_bg_threshold = max_bg_threshold\n\n        aug_transforms = AugmentationTransforms(self.image_size)\n\n        self.preprocess_transforms = aug_transforms.get_preprocessing()\n        self.train_transforms = aug_transforms.get_training_augmentation()\n        self.val_transforms = aug_transforms.get_validation_augmentation()\n\n    def setup(self, stage: Optional[str] = None):\n        if stage == \"fit\":\n            train_csv = pd.read_csv(\n                \"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/train.csv\"\n            )\n            train_csv[\"has_mask\"] = False\n            \n            # Mark examples that have masks available\n            masks_dir = Path(\"/kaggle/input/ubc-ocean-tiles-w-masks-2048px-scale-0-25/train_masks\")\n            for idx, row in train_csv.iterrows():\n                if (masks_dir / str(row['image_id'])).exists():\n                    train_csv.at[idx, \"has_mask\"] = True\n            \n            cutoff_point = int(len(train_csv) * self.cutoff)\n\n            self.train_dataset = CancerDataset(\n                train_csv.iloc[:cutoff_point],\n                self.black_threshold,\n                self.max_bg_threshold,\n                self.preprocess_transforms,\n                self.train_transforms,\n            )\n            self.validation_dataset = CancerDataset(\n                train_csv.iloc[cutoff_point:],\n                self.black_threshold,\n                self.max_bg_threshold,\n                self.preprocess_transforms,\n                self.val_transforms,\n            )\n\n            print(f\"The the training set has {len(self.train_dataset)} images\")\n            print(f\"The the validation set has {len(self.validation_dataset)} images\")\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.train_batch_size,\n            shuffle=self.shuffle,\n            num_workers=4,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.validation_dataset,\n            batch_size=8,\n            shuffle=False,\n            num_workers=4,\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:40:04.061987Z","iopub.execute_input":"2023-12-15T19:40:04.062426Z","iopub.status.idle":"2023-12-15T19:40:04.083502Z","shell.execute_reply.started":"2023-12-15T19:40:04.062364Z","shell.execute_reply":"2023-12-15T19:40:04.082286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.classification import (\n    MulticlassAccuracy,\n    MulticlassPrecision,\n    MulticlassRecall,\n    MulticlassF1Score,\n)\nfrom torchmetrics import MetricCollection\nimport timm\n\n\nclass CancerDetector(pl.LightningModule):\n    def __init__(\n        self,\n        lr: float,\n        gamma: float,\n        model_name: str,\n        warmup_epochs: int = 4,\n        num_classes: int = 5,\n        use_pretrain: bool = True,\n    ):\n        super().__init__()\n        # TODO Use model preprocessing function\n        self.model = self._get_model(model_name, num_classes, use_pretrain)\n\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.lr = lr\n        self.gamma = gamma\n        self.warmup_epochs = warmup_epochs\n\n        self.save_hyperparameters()\n\n        # Should we use micro average? Default is macro\n        metrics = MetricCollection(\n            [\n                MulticlassAccuracy(num_classes),\n                MulticlassF1Score(num_classes),\n                MulticlassPrecision(num_classes),\n                MulticlassRecall(num_classes),\n            ]\n        )\n        self.train_metrics = metrics.clone(prefix=\"train/\")\n        self.valid_metrics = metrics.clone(prefix=\"val/\")\n\n        self.train_step_outputs = []\n        self.validation_step_outputs = []\n\n    def _get_model(self, model_name: str, num_classes: int, use_pretrain: bool):\n        if model_name == \"efficientnet_b4\":\n            model = timm.create_model(\"efficientnet-b4\", pretrained=use_pretrain, num_classes=num_classes)\n        elif model_name == \"efficientnet_b5\":    \n            model = timm.create_model(\"efficientnet-b5\", pretrained=use_pretrain, num_classes=num_classes)\n        elif model_name == \"tiny_vit_21m_384\":    \n            model = timm.create_model(\"tiny_vit_21m_384\", pretrained=use_pretrain, num_classes=num_classes)\n        elif model_name == \"convnextv2_tiny\":    \n            model = timm.create_model(\"convnextv2_tiny\", pretrained=use_pretrain, num_classes=num_classes)\n        else:\n            raise Exception(f\"Unknown model name {model_name}\")\n        \n        return model\n\n    def forward(self, imgs: torch.Tensor):\n        return self.model(imgs)\n\n    def training_step(self, batch: torch.Tensor, batch_idx: int):\n        x, y = batch\n        output = self(x)\n        loss = self.loss_fn(output, y)\n\n        self.train_metrics.update(output, y)\n        self.train_step_outputs.append(loss.detach().item())\n        \n        return loss\n\n    def validation_step(self, batch: torch.Tensor, batch_idx: int):\n        x, y = batch\n        output = self(x)\n        loss = self.loss_fn(output, y)\n\n        self.valid_metrics.update(output, y)\n        self.validation_step_outputs.append(loss.detach().item())\n\n        return loss\n    \n    def on_train_epoch_end(self):\n        loss = np.mean(self.train_step_outputs)\n        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n\n        output = self.train_metrics.compute()\n        self.log_dict(output)\n\n        self.train_metrics.reset()\n        self.train_step_outputs.clear()\n        \n    def on_validation_epoch_end(self):\n        if not self.trainer.sanity_checking:\n            loss = np.mean(self.validation_step_outputs)\n            self.log(\"val/loss\", loss, on_step=False, on_epoch=True)\n\n            output = self.valid_metrics.compute()\n            self.log_dict(output)\n\n        self.valid_metrics.reset()\n        self.validation_step_outputs.clear()\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr)\n        \n        warmup = optim.lr_scheduler.LinearLR(optimizer, total_iters=self.warmup_epochs)\n        exponential = optim.lr_scheduler.ExponentialLR(optimizer, gamma=self.gamma)\n        scheduler = optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, exponential], milestones=[self.warmup_epochs])\n        \n        return [optimizer], [scheduler]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:40:04.084552Z","iopub.execute_input":"2023-12-15T19:40:04.085789Z","iopub.status.idle":"2023-12-15T19:40:04.861161Z","shell.execute_reply.started":"2023-12-15T19:40:04.085560Z","shell.execute_reply":"2023-12-15T19:40:04.859890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization\nVisualize inputs before the network","metadata":{}},{"cell_type":"code","source":"# Visualize input images\ndef visualize_input(datamodule: pl.LightningDataModule):\n    mean=np.array([0.8894420586142374,0.8208752169441305,0.8864016141389351]) * 255\n    std=np.array([0.10106393015358608,0.15637655015581306,0.09892687853183287]) * 255\n    \n    datamodule.prepare_data()\n    datamodule.setup(\"fit\")\n    train = datamodule.train_dataloader()\n    imgs, labels = next(iter(train))\n    \n    # B x C x H x W to B x H x W x C\n    imgs = imgs.permute((0,2,3,1))\n    imgs = imgs * std + mean\n    # Change the order of channels\n    imgs = imgs.flip(3)\n    imgs = imgs.numpy().astype('uint8')\n    \n    classes = ['HGSC', 'LGSC', 'EC', 'CC', 'MC']\n    idx2class = {idx: class_name for idx, class_name in enumerate(classes)}\n    \n    plt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\n\n    for i, (img, label) in enumerate(zip(imgs, labels)):\n        plt.subplot(4, 4, 1 + i)\n        plt.imshow(img)\n        plt.title(idx2class[label.item()])\n        plt.axis('off')\n        \n        if i == 15:\n            break\n            \n    plt.show()\n    \ncancer_module = CancerDataModule(320, 16, 0.8, 15)\nvisualize_input(cancer_module)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:40:04.863043Z","iopub.execute_input":"2023-12-15T19:40:04.863606Z","iopub.status.idle":"2023-12-15T19:40:57.633157Z","shell.execute_reply.started":"2023-12-15T19:40:04.863567Z","shell.execute_reply":"2023-12-15T19:40:57.632368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"!echo -e \"machine api.wandb.ai\\n  login user\\n  password 33b28a5d3e362bc21dfe1fc1759af32fdd74dec0\" >> /root/.netrc","metadata":{"execution":{"iopub.status.busy":"2023-12-16T06:20:25.299132Z","iopub.execute_input":"2023-12-16T06:20:25.299828Z","iopub.status.idle":"2023-12-16T06:20:26.232080Z","shell.execute_reply.started":"2023-12-16T06:20:25.299793Z","shell.execute_reply":"2023-12-16T06:20:26.230752Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import wandb\n\n# # Example sweep configuration\n# sweep_configuration= {\n#     \"method\": \"random\",\n#     \"name\": \"sweep\",\n#     \"metric\": {\"goal\": \"maximize\", \"name\": \"val/MulticlassF1Score\"},\n#     \"parameters\": {\n#         \"batch_size\": {\"values\": [8, 16]},\n#         \"lr\": {\"distribution\": \"log_uniform_values\", \"max\": 0.03, \"min\": 3e-5},\n#         \"lr_decay_gamma\": {\"distribution\": \"uniform\", \"max\": 0.998, \"min\": 0.99},\n#         \"model_name\": {\"values\": [\"efficientnet-b5\", \"tiny_vit_21m_384\", \"convnextv2_tiny\"]}\n#     },\n# }\n\n# sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"UBC Ovarian Cancer Classification\")","metadata":{"execution":{"iopub.status.busy":"2023-12-16T06:20:29.259823Z","iopub.execute_input":"2023-12-16T06:20:29.260220Z","iopub.status.idle":"2023-12-16T06:20:30.571777Z","shell.execute_reply.started":"2023-12-16T06:20:29.260183Z","shell.execute_reply":"2023-12-16T06:20:30.570839Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Create sweep with ID: ahjvv36h\nSweep URL: https://wandb.ai/malev/UBC%20Ovarian%20Cancer%20Classification/sweeps/ahjvv36h\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\nmain_config = {\n    \"warmup_epochs\": 5,\n    \"input_size\": 448,\n    \"train_val_cutoff\": 0.8,\n    \"black_threshold\": 15,\n    \"max_bg_threshold\": 0.3,\n    \"epochs\": 350,\n}\n\ndef train():\n    run = wandb.init()\n\n    hyperparameters = wandb.config\n    config = main_config | dict(hyperparameters)\n    \n    pl.seed_everything(seed=31415, workers=True)\n\n    wandb_logger = WandbLogger(project=\"UBC Ovarian Cancer Classification\", log_model=False, id=run.id, name=run.name)\n    model = CancerDetector(\n        lr=config[\"lr\"],\n        gamma=config[\"lr_decay_gamma\"],\n        model_name=config[\"model_name\"],\n        warmup_epochs=config[\"warmup_epochs\"],\n    )\n    cancer_module = CancerDataModule(\n        config[\"input_size\"],\n        config[\"batch_size\"],\n        cutoff=config[\"train_val_cutoff\"],\n        black_threshold=config[\"black_threshold\"],\n        max_bg_threshold=config[\"max_bg_threshold\"],\n    )\n\n    # Initialize callbacks\n    lr_monitor = LearningRateMonitor()\n    early_stopping = EarlyStopping(\n        monitor=\"val/MulticlassF1Score\", min_delta=0.0001, patience=25, mode=\"max\"\n    )\n    checkpoints = ModelCheckpoint(\n        monitor=\"train/MulticlassF1Score\" if config[\"train_val_cutoff\"] == 1.0 else \"val/MulticlassF1Score\",\n        save_top_k=3,\n        mode=\"max\",\n        save_weights_only=True,\n        save_last=True,\n        auto_insert_metric_name=False,\n        filename=\"epoch={epoch}-loss={val/loss:.4f}-f1={val/MulticlassF1Score:.4f}\",\n    )\n\n    # To disable validation, set limit_val_batches=0\n    enable_val = 0 if config[\"train_val_cutoff\"] == 1.0 else 1.0\n    print(enable_val)\n    trainer = pl.Trainer(\n        logger=wandb_logger,\n        max_epochs=config[\"epochs\"],\n        accelerator=\"gpu\",\n        devices=1,\n        limit_val_batches=enable_val,\n        precision=\"16-mixed\",\n        callbacks=[lr_monitor, checkpoints], #early_stopping,\n    )\n\n    trainer.fit(model, datamodule=cancer_module)\n    print(trainer.checkpoint_callback.best_model_path)\n\n    with open(\"best_model.txt\", \"w\") as f:\n        f.write(trainer.checkpoint_callback.best_model_path)\n\n    trainer.save_checkpoint(\"cancer_classification_model.pt\")\n    \n    \nwandb.agent(\"ahjvv36h\", function=train, project=\"UBC Ovarian Cancer Classification\", count=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:42:30.042888Z","iopub.execute_input":"2023-12-15T19:42:30.043221Z","iopub.status.idle":"2023-12-15T19:43:26.670785Z","shell.execute_reply.started":"2023-12-15T19:42:30.043197Z","shell.execute_reply":"2023-12-15T19:43:26.670063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert to ONNX","metadata":{}},{"cell_type":"code","source":"model = CancerDetector.load_from_checkpoint(\n    \"cancer_classification_model.pt\", use_pretrain=False\n)\nmodel.eval()\n\nx = torch.randn(1, 3, config[\"input_size\"], config[\"input_size\"], requires_grad=True)\n\n# Export the model\nmodel.to_onnx(\n    \"cancer_classification_model.onnx\",\n    x,\n    opset_version=17,\n    do_constant_folding=True,\n    input_names=[\"input\"],\n    output_names=[\"output\"],\n    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T17:23:43.434891Z","iopub.execute_input":"2023-12-14T17:23:43.435358Z","iopub.status.idle":"2023-12-14T17:23:48.940185Z","shell.execute_reply.started":"2023-12-14T17:23:43.435319Z","shell.execute_reply":"2023-12-14T17:23:48.938677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip download onnxruntime","metadata":{"execution":{"iopub.status.busy":"2023-12-14T17:23:52.564439Z","iopub.execute_input":"2023-12-14T17:23:52.564876Z","iopub.status.idle":"2023-12-14T17:23:58.402374Z","shell.execute_reply.started":"2023-12-14T17:23:52.564839Z","shell.execute_reply":"2023-12-14T17:23:58.400507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- https://huggingface.co/timm/efficientnet_b5.sw_in12k_ft_in1k input size 448\n- https://huggingface.co/timm/tf_efficientnet_b4.ns_jft_in1k input size 380\n- tf_efficientnetv2_s_in21ft1k\n- tf_efficientnet_b4.ns_jft_in1k\n- tiny_vit_21m_384.dist_in22k_ft_in1k\n- edgenext_base.in21k_ft_in1k","metadata":{}}]}